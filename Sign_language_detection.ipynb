import kagglehub

# Download latest version
path = kagglehub.dataset_download("debashishsau/aslamerican-sign-language-aplhabet-dataset")

print("Path to dataset files:", path)

# lets preprocess the data

# we need to import imagedataGenerator to rescale images and split training and testing datta

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# data generator object

import os

base_path = "/root/.cache/kagglehub/datasets/debashishsau/aslamerican-sign-language-aplhabet-dataset/versions/1"

print("Folders here:", os.listdir(base_path))


#so thats the reason its not going one level deep so lets do this

path = base_path + "/ASL_Alphabet_Dataset"

datagen = ImageDataGenerator(rescale=1./255,validation_split=0.2)

import kagglehub

path = kagglehub.dataset_download("debashishsau/aslamerican-sign-language-aplhabet-dataset")

print("Dataset downloaded at:", path)

import os
print("Files at dataset path:", os.listdir(path))


import os

dataset_path = "/kaggle/input/aslamerican-sign-language-aplhabet-dataset/ASL_Alphabet_Dataset"

print("Contents of ASL_Alphabet_Dataset:")
print(os.listdir(dataset_path))


# Set correct dataset path to training data
dataset_path = "/kaggle/input/aslamerican-sign-language-aplhabet-dataset/ASL_Alphabet_Dataset/asl_alphabet_train"

# Data generator with rescaling and validation split
datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

# Training generator
train_generator = datagen.flow_from_directory(
    directory=dataset_path,
    target_size=(64, 64),
    batch_size=32,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

# Validation generator
val_generator = datagen.flow_from_directory(
    directory=dataset_path,
    target_size=(64, 64),
    batch_size=32,
    class_mode='categorical',
    subset='validation',
    shuffle=True
)


# we are done with preprocessing successfully

#now lets create a simple cnn model

import tensorflow as tf
from tensorflow.keras import layers,models

model = models.Sequential([
    layers.Conv2D(32 , (3,3), activation = 'relu' ,input_shape = (64,64,3)),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(64 , (3,3), activation = 'relu'),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(128 , (3,3), activation = 'relu'),
    layers.MaxPooling2D(2,2),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(29, activation='softmax')
])

#compile the model

model.compile(
    optimizer = "adam",
    loss = "categorical_crossentropy",
    metrics = ["accuracy"]
)

#now lets train the model using generators and fit the model

history = model.fit(
    train_generator,
    epochs = 10,
    validation_data = val_generator
)

#Done with training after long 5 hours

#lets save the model in both formats h5 and keras 

model.save("sign_language_model.keras")

#lets plot the graphs to understand the metrics here

import matplotlib.pyplot as plt

# Accuracy plot
plt.plot(history.history['accuracy'], label='train acc')
plt.plot(history.history['val_accuracy'], label='val acc')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Loss plot
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()


#lets create a web app using gradio

!pip install gradio

import gradio as gr
from tensorflow.keras.models import load_model
import numpy as np
import cv2

# Load model
model = load_model("sign_language_model.h5")

class_indices = train_generator.class_indices
classes = {v: k for k, v in class_indices.items()}


#prediction

def predict_sign(image):
    # Resize image to model input size
    img = cv2.resize(image, (64, 64))
    img = img / 255.0
    img = np.expand_dims(img, axis=0)

    # Predict
    prediction = model.predict(img)
    class_index = np.argmax(prediction)
    class_label = classes[class_index]

    return f"Predicted Sign: {class_label}"


interface = gr.Interface(
    fn=predict_sign,
    inputs=gr.Image(type="numpy", label="Webcam Input", sources=["webcam", "upload"]),
    outputs=gr.Textbox(label="Prediction"),
    title="ASL Sign Language Detection",
    description="Use your webcam or upload an image of a hand sign to predict the ASL letter."
)

interface.launch()


#Successfully made a Sign Language Detection model with an improved accuracy of 80 % Success rate
